"{\"py/object\": \"__main__.Document\", \"auto\": true, \"title\": \"Create the infrastructure for deploying Apache Airflow on Azure Kubernetes Service (AKS)\", \"description\": \"\\n\\nCurrent content for this file is copied below. You should use this as a guide for the content you create, but should ensure that it is a valid executable doc and improve on readability wherever possible:\\n\\n---\\ntitle: Create the infrastructure for deploying Apache Airflow on Azure Kubernetes Service (AKS)\\ndescription: In this article, you create the infrastructure needed to deploy Apache Airflow on Azure Kubernetes Service (AKS) using Helm.\\nms.topic: how-to\\nms.custom: azure-kubernetes-service\\nms.date: 12/19/2024\\nauthor: schaffererin\\nms.author: schaffererin\\n---\\n\\n# Create the infrastructure for running Apache Airflow on Azure Kubernetes Service (AKS)\\n\\nIn this article, you create the infrastructure required to run Apache Airflow on Azure Kubernetes Service (AKS).\\n\\n## Prerequisites\\n\\n* If you haven't already, review the [Overview for deploying an Apache Airflow cluster on Azure Kubernetes Service (AKS)](./airflow-overview.md).\\n* An Azure subscription. If you don't have one, create a [free account](https://azure.microsoft.com/free/?WT.mc_id=A261C142F).\\n* Azure CLI version 2.61.0. To install or upgrade, see [Install Azure CLI](/cli/azure/install-azure-cli).\\n* Helm version 3 or later. To install, see [Installing Helm](https://helm.sh/docs/intro/install/).\\n* `kubectl`, which is installed in Azure Cloud Shell by default.\\n* GitHub Repo to store Airflow Dags.\\n* Docker installed on your local machine. To install, see [Get Docker](https://docs.docker.com/get-docker/).\\n\\n## Set environment variables\\n\\n* Set the required environment variables for use throughout this guide:\\n\\n    ```bash\\n    random=$(echo $RANDOM | tr '[0-9]' '[a-z]')\\n    export MY_LOCATION=canadacentral\\n    export MY_RESOURCE_GROUP_NAME=apache-airflow-rg\\n    export MY_IDENTITY_NAME=airflow-identity-123\\n    export MY_ACR_REGISTRY=mydnsrandomname$(echo $random)\\n    export MY_KEYVAULT_NAME=airflow-vault-$(echo $random)-kv\\n    export MY_CLUSTER_NAME=apache-airflow-aks\\n    export SERVICE_ACCOUNT_NAME=airflow\\n    export SERVICE_ACCOUNT_NAMESPACE=airflow\\n    export AKS_AIRFLOW_NAMESPACE=airflow\\n    export AKS_AIRFLOW_CLUSTER_NAME=cluster-aks-airflow\\n    export AKS_AIRFLOW_LOGS_STORAGE_ACCOUNT_NAME=airflowsasa$(echo $random)\\n    export AKS_AIRFLOW_LOGS_STORAGE_CONTAINER_NAME=airflow-logs\\n    export AKS_AIRFLOW_LOGS_STORAGE_SECRET_NAME=storage-account-credentials\\n    ```\\n\\n## Create a resource group\\n\\n* Create a resource group using the [`az group create`](/cli/azure/group#az-group-create) command.\\n\\n    ```azurecli-interactive\\n    az group create --name $MY_RESOURCE_GROUP_NAME --location $MY_LOCATION --output table\\n    ```\\n\\n    Example output:\\n    <!-- expected_similarity=0.8 -->\\n    ```output\\n    Location       Name\\n    -------------  -----------------\\n    $MY_LOCATION   $MY_RESOURCE_GROUP_NAME\\n    ```\\n\\n## Create an identity to access secrets in Azure Key Vault\\n\\nIn this step, we create a user-assigned managed identity that the External Secrets Operator uses to access the Airflow passwords stored in Azure Key Vault.\\n\\n* Create a user-assigned managed identity using the [`az identity create`](/cli/azure/identity#az-identity-create) command.\\n\\n    ```azurecli-interactive\\n    az identity create --name $MY_IDENTITY_NAME --resource-group $MY_RESOURCE_GROUP_NAME --output table\\n    export MY_IDENTITY_NAME_ID=$(az identity show --name $MY_IDENTITY_NAME --resource-group $MY_RESOURCE_GROUP_NAME --query id --output tsv)\\n    export MY_IDENTITY_NAME_PRINCIPAL_ID=$(az identity show --name $MY_IDENTITY_NAME --resource-group $MY_RESOURCE_GROUP_NAME --query principalId --output tsv)\\n    export MY_IDENTITY_NAME_CLIENT_ID=$(az identity show --name $MY_IDENTITY_NAME --resource-group $MY_RESOURCE_GROUP_NAME --query clientId --output tsv)\\n    ```\\n\\n    Example output:\\n    <!-- expected_similarity=0.8 -->\\n    ```output\\n    ClientId                              Location       Name                  PrincipalId                           ResourceGroup            TenantId\\n    ------------------------------------  -------------  --------------------  ------------------------------------  -----------------------  ------------------------------------  \\n    00001111-aaaa-2222-bbbb-3333cccc4444  $MY_LOCATION   $MY_IDENTITY_NAME     aaaaaaaa-bbbb-cccc-1111-222222222222  $MY_RESOURCE_GROUP_NAME  aaaabbbb-0000-cccc-1111-dddd2222eeee \\n    ```\\n\\n## Create an Azure Key Vault instance\\n\\n* Create an Azure Key Vault instance using the [`az keyvault create`](/cli/azure/keyvault#az-keyvault-create) command.\\n\\n    ```azurecli-interactive\\n    az keyvault create --name $MY_KEYVAULT_NAME --resource-group $MY_RESOURCE_GROUP_NAME --location $MY_LOCATION --enable-rbac-authorization false --output table\\n    export KEYVAULTID=$(az keyvault show --name $MY_KEYVAULT_NAME --query \\\"id\\\" --output tsv)\\n    export KEYVAULTURL=$(az keyvault show --name $MY_KEYVAULT_NAME --query \\\"properties.vaultUri\\\" --output tsv)\\n    ```\\n\\n    Example output:\\n    <!-- expected_similarity=0.8 -->\\n    ```output\\n    Location       Name                  ResourceGroup\\n    -------------  --------------------  ----------------------\\n    $MY_LOCATION   $MY_KEYVAULT_NAME     $MY_RESOURCE_GROUP_NAME\\n    ```\\n\\n## Create an Azure Container Registry\\n\\n* Create an Azure Container Registry to store and manage your container images using the [`az acr create`](/cli/azure/acr#az-acr-create) command.\\n\\n    ```azurecli-interactive\\n    az acr create \\\\\\n    --name ${MY_ACR_REGISTRY} \\\\\\n    --resource-group $MY_RESOURCE_GROUP_NAME \\\\\\n    --sku Premium \\\\\\n    --location $MY_LOCATION \\\\\\n    --admin-enabled true \\\\\\n    --output table\\n    export MY_ACR_REGISTRY_ID=$(az acr show --name $MY_ACR_REGISTRY --resource-group $MY_RESOURCE_GROUP_NAME --query id --output tsv)\\n    ```\\n\\n    Example output:\\n    <!-- expected_similarity=0.8 -->\\n    ```output\\n    NAME                  RESOURCE GROUP           LOCATION       SKU      LOGIN SERVER                     CREATION DATE         ADMIN ENABLED\\n    --------------------  ----------------------   -------------  -------  -------------------------------  --------------------  ---------------\\n    mydnsrandomnamebfbje  $MY_RESOURCE_GROUP_NAME  $MY_LOCATION   Premium  mydnsrandomnamebfbje.azurecr.io  2024-11-07T00:32:48Z  True\\n    ```\\n\\n## Create an Azure storage account\\n\\n* Create an Azure Storage Account to store the Airflow logs using the [`az acr create`](/cli/azure/storage/account#az-storage-account-create) command.\\n\\n    ```azurecli-interactive\\n    az storage account create --name $AKS_AIRFLOW_LOGS_STORAGE_ACCOUNT_NAME --resource-group $MY_RESOURCE_GROUP_NAME --location $MY_LOCATION --sku Standard_ZRS --output table\\n    export AKS_AIRFLOW_LOGS_STORAGE_ACCOUNT_KEY=$(az storage account keys list --account-name $AKS_AIRFLOW_LOGS_STORAGE_ACCOUNT_NAME --query \\\"[0].value\\\" -o tsv)\\n    az storage container create --name $AKS_AIRFLOW_LOGS_STORAGE_CONTAINER_NAME --account-name $AKS_AIRFLOW_LOGS_STORAGE_ACCOUNT_NAME --output table --account-key $AKS_AIRFLOW_LOGS_STORAGE_ACCOUNT_KEY\\n    az keyvault secret set --vault-name $MY_KEYVAULT_NAME --name AKS-AIRFLOW-LOGS-STORAGE-ACCOUNT-NAME --value $AKS_AIRFLOW_LOGS_STORAGE_ACCOUNT_NAME\\n    az keyvault secret set --vault-name $MY_KEYVAULT_NAME --name AKS-AIRFLOW-LOGS-STORAGE-ACCOUNT-KEY --value $AKS_AIRFLOW_LOGS_STORAGE_ACCOUNT_KEY\\n    ```\\n\\n    Example output:\\n    <!-- expected_similarity=0.8 -->\\n    ```output\\n    AccessTier    AllowBlobPublicAccess    AllowCrossTenantReplication    CreationTime                      EnableHttpsTrafficOnly    Kind       Location       MinimumTlsVersion    Name              PrimaryLocation    ProvisioningState    ResourceGroup      StatusOfPrimary\\n    ------------  -----------------------  -----------------------------  --------------------------------  ------------------------  ---------  -------------  -------------------  ----------------  -----------------  -------------------  -----------------  -----------------\\n    Hot           False                    False                          2024-11-07T00:22:13.323104+00:00  True                      StorageV2  $MY_LOCATION   TLS1_0               airflowsasabfbje  $MY_LOCATION       Succeeded            $MY_RESOURCE_GROUP_NAME  available\\n    Created\\n    ---------\\n    True\\n    ```\\n\\n## Create an AKS cluster\\n\\nIn this step, we create an AKS cluster with workload identity and OIDC issuer enabled. The workload identity gives the External Secrets Operator service account permission to access the Airflow passwords stored in your key vault.\\n\\n1. Create an AKS cluster using the [`az aks create`](/cli/azure/aks#az-aks-create) command.\\n\\n    ```azurecli-interactive\\n    az aks create \\\\\\n    --location $MY_LOCATION \\\\\\n    --name $MY_CLUSTER_NAME \\\\\\n    --tier standard \\\\\\n    --resource-group $MY_RESOURCE_GROUP_NAME \\\\\\n    --network-plugin azure  \\\\\\n    --node-vm-size Standard_DS4_v2 \\\\\\n    --node-count 3 \\\\\\n    --auto-upgrade-channel stable \\\\\\n    --node-os-upgrade-channel NodeImage \\\\\\n    --attach-acr ${MY_ACR_REGISTRY} \\\\\\n    --enable-oidc-issuer \\\\\\n    --enable-blob-driver \\\\\\n    --enable-workload-identity \\\\\\n    --zones 1 2 3 \\\\\\n    --generate-ssh-keys \\\\\\n    --output table\\n    ```\\n\\n    Example output:\\n    <!-- expected_similarity=0.5 -->\\n    ```output\\n    AzurePortalFqdn                                                                 CurrentKubernetesVersion    DisableLocalAccounts    DnsPrefix                           EnableRbac    Fqdn                                                                     KubernetesVersion    Location       MaxAgentPools    Name                NodeResourceGroup                                      ProvisioningState    ResourceGroup            ResourceUid                           SupportPlan\\n    ------------------------------------------------------------------------------  --------------------------  ----------------------  ----------------------------------  ------------  -----------------------------------------------------------------------  -------------------  -------------  ---------------  ------------------  -----------------------------------------------------  -------------------  -----------------------  ------------------------------------  ------------------\\n    apache-air-apache-airflow-r-363a0a-rhf6saad.portal.hcp.$MY_LOCATION.azmk8s.io   1.29.9                      False                   apache-air-apache-airflow-r-363a0a  True          apache-air-apache-airflow-r-363a0a-rhf6saad.hcp.$MY_LOCATION.azmk8s.io   1.29                 $MY_LOCATION   100              $MY_CLUSTER_NAME    MC_apache-airflow-rg_apache-airflow-aks_$MY_LOCATION   Succeeded            $MY_RESOURCE_GROUP_NAME  b1b1b1b1-cccc-dddd-eeee-f2f2f2f2f2f2  KubernetesOfficial\\n    ```\\n\\n2. Get the OIDC issuer URL to use for the workload identity configuration using the [`az aks show`](/cli/azure/aks#az-aks-show) command.\\n\\n    ```azurecli-interactive\\n    export OIDC_URL=$(az aks show --resource-group $MY_RESOURCE_GROUP_NAME --name $MY_CLUSTER_NAME --query oidcIssuerProfile.issuerUrl --output tsv)\\n    ```\\n\\n3. Assign the `AcrPull` role to the kubelet identity using the [`az role assignment create`](/cli/azure/role/assignment#az-role-assignment-create) command.\\n\\n    ```azurecli-interactive\\n    export KUBELET_IDENTITY=$(az aks show -g $MY_RESOURCE_GROUP_NAME --name $MY_CLUSTER_NAME --output tsv --query identityProfile.kubeletidentity.objectId)\\n    az role assignment create \\\\\\n    --assignee ${KUBELET_IDENTITY} \\\\\\n    --role \\\"AcrPull\\\" \\\\\\n    --scope ${MY_ACR_REGISTRY_ID} \\\\\\n    --output table\\n    ```\\n\\n    Example output:\\n    <!-- expected_similarity=0.8 -->\\n    ```output\\n    CreatedBy                             CreatedOn                         Name                                  PrincipalId                           PrincipalName                         PrincipalType     ResourceGroup            RoleDefinitionId                                                                                                                            RoleDefinitionName    Scope                                                                                                                                                             UpdatedBy                             UpdatedOn\\n    ------------------------------------  --------------------------------  ------------------------------------  ------------------------------------  ------------------------------------  ----------------  -----------------------  ------------------------------------------------------------------------------------------------------------------------------------------  --------------------  ----------------------------------------------------------------------------------------------------------------------------------------------------------        ------------------------------------  --------------------------------\\n    ccccdddd-2222-eeee-3333-ffff4444aaaa  2024-11-07T00:43:26.905445+00:00  b1b1b1b1-cccc-dddd-eeee-f2f2f2f2f2f2  bbbbbbbb-cccc-dddd-2222-333333333333  cccccccc-dddd-eeee-3333-444444444444  ServicePrincipal  $MY_RESOURCE_GROUP_NAME  /subscriptions/aaaa0a0a-bb1b-cc2c-dd3d-eeeeee4e4e4e/providers/Microsoft.Authorization/roleDefinitions/7f951dda-4ed3-4680-a7ca-43fe172d538d  AcrPull               /subscriptions/aaaa0a0a-bb1b-cc2c-dd3d-eeeeee4e4e4e/resourceGroups/$MY_RESOURCE_GROUP_NAME/providers/Microsoft.ContainerRegistry/registries/mydnsrandomnamebfbje  ccccdddd-2222-eeee-3333-ffff4444aaaa  2024-11-07T00:43:26.905445+00:00\\n    ```\\n\\n## Connect to the AKS cluster\\n\\n* Configure `kubectl` to connect to your AKS cluster using the [`az aks get-credentials`](/cli/azure/aks#az-aks-get-credentials) command.\\n\\n    ```azurecli-interactive\\n    az aks get-credentials --resource-group $MY_RESOURCE_GROUP_NAME --name $MY_CLUSTER_NAME --overwrite-existing --output table\\n    ```\\n\\n## Upload Apache Airflow images to your container registry\\n\\nIn this section, we download the Apache Airflow images from Docker Hub and upload them to Azure Container Registry. This step ensures that the images are available in your private registry and can be used in your AKS cluster. We don't recommend consuming the public image in a production environment.\\n\\n* Import the Airflow images from Docker Hub and upload them to your container registry using the [`az acr import`](/cli/azure/acr#az-acr-import) command.\\n\\n    ```azurecli-interactive\\n    az acr import --name $MY_ACR_REGISTRY --source docker.io/apache/airflow:airflow-pgbouncer-2024.01.19-1.21.0 --image airflow:airflow-pgbouncer-2024.01.19-1.21.0\\n    az acr import --name $MY_ACR_REGISTRY --source docker.io/apache/airflow:airflow-pgbouncer-exporter-2024.06.18-0.17.0 --image airflow:airflow-pgbouncer-exporter-2024.06.18-0.17.0\\n    az acr import --name $MY_ACR_REGISTRY --source docker.io/bitnami/postgresql:16.1.0-debian-11-r15 --image postgresql:16.1.0-debian-11-r15\\n    az acr import --name $MY_ACR_REGISTRY --source quay.io/prometheus/statsd-exporter:v0.26.1 --image statsd-exporter:v0.26.1 \\n    az acr import --name $MY_ACR_REGISTRY --source docker.io/apache/airflow:2.9.3 --image airflow:2.9.3 \\n    az acr import --name $MY_ACR_REGISTRY --source registry.k8s.io/git-sync/git-sync:v4.1.0 --image git-sync:v4.1.0\\n    ```\\n\\n## Next step\\n\\n> [!div class=\\\"nextstepaction\\\"]\\n> [Deploy Apache Airflow on Azure Kubernetes Service (AKS)](./airflow-deploy.md)\\n\\n## Contributors\\n\\n*Microsoft maintains this article. The following contributors originally wrote it:*\\n\\n* Don High | Principal Customer Engineer\\n* Satya Chandragiri | Senior Digital Cloud Solution Architect\\n* Erin Schaffer | Content Developer 2\\n\", \"published_source\": \"https://raw.githubusercontent.com/MicrosoftDocs/azure-aks-docs/refs/heads/main/articles/aks/airflow-create-infrastructure.md\", \"meta_data\": {}, \"sections\": [{\"py/object\": \"__main__.Section\", \"name\": \"Overview\", \"requires_test\": false, \"instance\": {\"py/object\": \"overview.Overview\", \"title\": \"Overview - Create the infrastructure for deploying Apache Airflow on Azure Kubernetes Service (AKS)\", \"meta_data\": {}, \"content\": \"## Overview\\n\\nThis document outlines the infrastructure required to deploy Apache Airflow on Azure Kubernetes Service (AKS). Apache Airflow is a powerful workflow orchestration tool used for automating complex data pipelines and workflows. By leveraging AKS, users can deploy Airflow in a scalable, secure, and highly available environment. This guide is tailored for scenarios where users need to deploy Airflow using Helm, ensuring efficient containerized deployment and management.\\n\\nUse cases for this architecture include orchestrating ETL processes, managing machine learning workflows, and automating data pipeline execution in a cloud-native environment. The document provides step-by-step instructions for setting up the necessary Azure resources, including identity management, storage, container registry, and Kubernetes cluster configuration.\\n\\n### Major Components\\n\\n* **Resource Group**: The resource group serves as the logical container for all Azure resources related to the Airflow deployment. It simplifies resource management and provides a unified billing structure.\\n* **Azure Key Vault**: Used to securely store secrets, such as Airflow passwords and sensitive configuration data. The External Secrets Operator accesses these secrets during runtime.\\n* **Azure Container Registry (ACR)**: Hosts the container images required for Apache Airflow and its dependencies. ACR ensures secure and efficient image management.\\n* **Azure Storage Account**: Provides storage for Airflow logs, enabling persistent and centralized logging for troubleshooting and monitoring.\\n* **Azure Kubernetes Service (AKS)**: Hosts the Apache Airflow deployment. AKS provides a managed Kubernetes environment with features like workload identity, OIDC issuer, and auto-scaling.\\n* **Managed Identity**: A user-assigned managed identity is created to allow secure access to Azure Key Vault secrets from the AKS cluster.\\n* **Helm**: A package manager for Kubernetes, used to deploy and manage Apache Airflow on AKS.\\n\\n### Decision Points\\n\\nIn this architecture, users will encounter several decision points that can impact the deployment's performance, cost, and scalability. Below are the key areas where decisions need to be made:\\n\\n1. **Resource Group Location**: Choose the Azure region where the resource group will be created. Factors to consider include proximity to data sources, compliance requirements, and latency.\\n2. **Azure Key Vault Configuration**: Decide whether to enable RBAC authorization for Key Vault. RBAC provides fine-grained access control but may require additional configuration.\\n3. **Azure Container Registry SKU**: Select the appropriate SKU (e.g., Basic, Standard, Premium) based on the expected image storage size and throughput requirements.\\n4. **Azure Storage Account SKU**: Choose a storage SKU (e.g., Standard_LRS, Standard_ZRS) based on redundancy and performance needs. Standard_ZRS offers higher availability.\\n5. **AKS Cluster Configuration**:\\n   - **Node VM Size**: Select the VM size for AKS nodes based on workload requirements. For example, Standard_DS4_v2 offers a balance of CPU and memory.\\n   - **Node Count**: Determine the number of nodes required for the cluster. This depends on workload concurrency and expected traffic.\\n   - **Auto-Upgrade Channel**: Decide whether to enable automatic upgrades for Kubernetes versions and node images.\\n   - **Network Plugin**: Choose between Azure CNI or Kubenet for networking. Azure CNI is recommended for advanced networking features.\\n6. **Container Images**: Decide whether to use public Docker Hub images or import them into a private Azure Container Registry for enhanced security.\\n7. **Helm Chart Configuration**: Configure Helm values for Airflow deployment, including resource limits, replica counts, and environment variables.\\n\\nEach decision should be guided by workload requirements, cost considerations, and operational preferences. Additional details for these decision points will be provided in the respective sections of the document.\\n\\n### Alternatives\\n\\nWhile this document focuses on deploying Apache Airflow on AKS, there are alternative Azure-based solutions that users may consider:\\n\\n1. **Azure App Service with Docker**: For simpler deployments, users can run Apache Airflow as a containerized application on Azure App Service. This approach reduces operational complexity but may lack the scalability and flexibility of AKS.\\n2. **Azure Batch**: For orchestrating large-scale batch processing workflows, Azure Batch can be an alternative to Airflow. It is optimized for parallel compute jobs but may not provide the same level of workflow orchestration.\\n3. **Azure Data Factory**: For data integration and ETL workflows, Azure Data Factory offers a managed service with built-in connectors and a visual interface. However, it is less customizable compared to Airflow.\\n4. **Self-Managed Kubernetes**: Users can deploy Apache Airflow on a self-managed Kubernetes cluster hosted on Azure VMs. This provides full control over the Kubernetes environment but requires significant operational overhead.\\n\\nEach alternative has trade-offs in terms of scalability, cost, and operational complexity. AKS is recommended for users seeking a managed Kubernetes solution with integrated Azure services and Helm-based deployment capabilities.\"}}, {\"py/object\": \"__main__.Section\", \"name\": \"Deployment\", \"requires_test\": true, \"instance\": {\"py/object\": \"deployment.Deployment\", \"title\": \"Deployment - Create the infrastructure for deploying Apache Airflow on Azure Kubernetes Service (AKS)\", \"meta_data\": {}, \"content\": \"## Prerequisites\\n\\nThe following prerequisites are required before you are able to work through this document.\\n\\n- Az CLI is installed and you are logged in to an active Azure subscription\\n\\n```bash\\nexport SUFFIX=$(date +%s%N | sha256sum | head -c 6)\\n```\\n\\n---\\n\\n## Step 1: Create Resource Group\\n\\nThe resource group serves as the logical container for all Azure resources related to the Airflow deployment. It simplifies resource management and provides a unified billing structure.\\n\\nDefine the environment variables for the resource group:\\n\\n```bash\\nexport RESOURCE_GROUP_NAME_ED432=\\\"AirflowRG_$SUFFIX\\\"\\nexport REGION_ED432=\\\"westus2\\\"\\n```\\n\\nCreate the resource group:\\n\\n```bash\\naz group create --name $RESOURCE_GROUP_NAME_ED432 \\\\\\n    --location $REGION_ED432\\n```\\n\\nThis command will output results similar to the following:\\n\\n<!-- expected_similarity=0.3 -->\\n\\n```text\\n{\\n    \\\"id\\\": \\\"/subscriptions/xxxxx-xxxxx-xxxxx-xxxxx/resourceGroups/AirflowRG_xxxxxx\\\",\\n    \\\"location\\\": \\\"westus2\\\",\\n    \\\"managedBy\\\": null,\\n    \\\"name\\\": \\\"AirflowRG_xxxxxx\\\",\\n    \\\"properties\\\": {\\n        \\\"provisioningState\\\": \\\"Succeeded\\\"\\n    },\\n    \\\"tags\\\": null,\\n    \\\"type\\\": \\\"Microsoft.Resources/resourceGroups\\\"\\n}\\n```\\n\\nThe choice of region impacts latency, compliance, and cost. WestUS2 is recommended for its availability and proximity to many data centers.\\n\\n---\\n\\n## Step 2: Create Azure Key Vault\\n\\nAzure Key Vault securely stores secrets, such as Airflow passwords and sensitive configuration data. The External Secrets Operator accesses these secrets during runtime.\\n\\nDefine the environment variables for the Key Vault:\\n\\n```bash\\nexport KEY_VAULT_NAME_ED432=\\\"airflowkv$SUFFIX\\\"\\n```\\n\\nCreate the Key Vault:\\n\\n```bash\\naz keyvault create --name $KEY_VAULT_NAME_ED432 \\\\\\n    --resource-group $RESOURCE_GROUP_NAME_ED432 \\\\\\n    --location $REGION_ED432 \\\\\\n    --sku standard\\n```\\n\\nThis command will output results similar to the following:\\n\\n<!-- expected_similarity=0.3 -->\\n\\n```text\\n{\\n    \\\"id\\\": \\\"/subscriptions/xxxxx-xxxxx-xxxxx-xxxxx/resourceGroups/AirflowRG_xxxxxx/providers/Microsoft.KeyVault/vaults/airflowkvxxxxxx\\\",\\n    \\\"location\\\": \\\"westus2\\\",\\n    \\\"name\\\": \\\"airflowkvxxxxxx\\\",\\n    \\\"properties\\\": {\\n        \\\"sku\\\": {\\n            \\\"family\\\": \\\"A\\\",\\n            \\\"name\\\": \\\"standard\\\"\\n        },\\n        \\\"vaultUri\\\": \\\"https://airflowkvxxxxxx.vault.azure.net/\\\"\\n    },\\n    \\\"type\\\": \\\"Microsoft.KeyVault/vaults\\\"\\n}\\n```\\n\\nConsider enabling RBAC authorization for finer-grained access control, especially in production environments.\\n\\n---\\n\\n## Step 3: Create Azure Container Registry (ACR)\\n\\nAzure Container Registry hosts the container images required for Apache Airflow and its dependencies. ACR ensures secure and efficient image management.\\n\\nDefine the environment variables for the ACR:\\n\\n```bash\\nexport ACR_NAME_ED432=\\\"airflowacr$SUFFIX\\\"\\n```\\n\\nCreate the ACR:\\n\\n```bash\\naz acr create --name $ACR_NAME_ED432 \\\\\\n    --resource-group $RESOURCE_GROUP_NAME_ED432 \\\\\\n    --location $REGION_ED432 \\\\\\n    --sku Standard\\n```\\n\\nThis command will output results similar to the following:\\n\\n<!-- expected_similarity=0.3 -->\\n\\n```text\\n{\\n    \\\"id\\\": \\\"/subscriptions/xxxxx-xxxxx-xxxxx-xxxxx/resourceGroups/AirflowRG_xxxxxx/providers/Microsoft.ContainerRegistry/registries/airflowacrxxxxxx\\\",\\n    \\\"location\\\": \\\"westus2\\\",\\n    \\\"name\\\": \\\"airflowacrxxxxxx\\\",\\n    \\\"properties\\\": {\\n        \\\"sku\\\": {\\n            \\\"name\\\": \\\"Standard\\\"\\n        },\\n        \\\"loginServer\\\": \\\"airflowacrxxxxxx.azurecr.io\\\"\\n    },\\n    \\\"type\\\": \\\"Microsoft.ContainerRegistry/registries\\\"\\n}\\n```\\n\\nThe Standard SKU is suitable for most workloads. Consider upgrading to Premium for higher throughput and geo-replication.\\n\\n---\\n\\n## Step 4: Create Azure Storage Account\\n\\nAzure Storage Account provides storage for Airflow logs, enabling persistent and centralized logging for troubleshooting and monitoring.\\n\\nDefine the environment variables for the storage account:\\n\\n```bash\\nexport STORAGE_ACCOUNT_NAME_ED432=\\\"airflowstorage$SUFFIX\\\"\\n```\\n\\nCreate the storage account:\\n\\n```bash\\naz storage account create --name $STORAGE_ACCOUNT_NAME_ED432 \\\\\\n    --resource-group $RESOURCE_GROUP_NAME_ED432 \\\\\\n    --location $REGION_ED432 \\\\\\n    --sku Standard_LRS\\n```\\n\\nThis command will output results similar to the following:\\n\\n<!-- expected_similarity=0.3 -->\\n\\n```text\\n{\\n    \\\"id\\\": \\\"/subscriptions/xxxxx-xxxxx-xxxxx-xxxxx/resourceGroups/AirflowRG_xxxxxx/providers/Microsoft.Storage/storageAccounts/airflowstoragexxxxxx\\\",\\n    \\\"location\\\": \\\"westus2\\\",\\n    \\\"name\\\": \\\"airflowstoragexxxxxx\\\",\\n    \\\"properties\\\": {\\n        \\\"provisioningState\\\": \\\"Succeeded\\\",\\n        \\\"primaryEndpoints\\\": {\\n            \\\"blob\\\": \\\"https://airflowstoragexxxxxx.blob.core.windows.net/\\\"\\n        }\\n    },\\n    \\\"sku\\\": {\\n        \\\"name\\\": \\\"Standard_LRS\\\"\\n    },\\n    \\\"type\\\": \\\"Microsoft.Storage/storageAccounts\\\"\\n}\\n```\\n\\nStandard_LRS is cost-effective and suitable for most workloads. Consider Standard_ZRS for higher availability.\\n\\n---\\n\\n## Step 5: Create Azure Kubernetes Service (AKS)\\n\\nAzure Kubernetes Service hosts the Apache Airflow deployment. AKS provides a managed Kubernetes environment with features like workload identity, OIDC issuer, and auto-scaling.\\n\\nDefine the environment variables for the AKS cluster:\\n\\n```bash\\nexport AKS_CLUSTER_NAME_ED432=\\\"AirflowAKS$SUFFIX\\\"\\nexport NODE_VM_SIZE_ED432=\\\"Standard_D4_v3\\\"\\nexport NODE_COUNT_ED432=3\\n```\\n\\nCreate the AKS cluster:\\n\\n```bash\\naz aks create --name $AKS_CLUSTER_NAME_ED432 \\\\\\n    --resource-group $RESOURCE_GROUP_NAME_ED432 \\\\\\n    --location $REGION_ED432 \\\\\\n    --node-vm-size $NODE_VM_SIZE_ED432 \\\\\\n    --node-count $NODE_COUNT_ED432 \\\\\\n    --enable-managed-identity \\\\\\n    --enable-oidc-issuer \\\\\\n    --network-plugin azure\\n```\\n\\nThis command will output results similar to the following:\\n\\n<!-- expected_similarity=0.3 -->\\n\\n```text\\n{\\n    \\\"id\\\": \\\"/subscriptions/xxxxx-xxxxx-xxxxx-xxxxx/resourceGroups/AirflowRG_xxxxxx/providers/Microsoft.ContainerService/managedClusters/AirflowAKSxxxxxx\\\",\\n    \\\"location\\\": \\\"westus2\\\",\\n    \\\"name\\\": \\\"AirflowAKSxxxxxx\\\",\\n    \\\"properties\\\": {\\n        \\\"provisioningState\\\": \\\"Succeeded\\\",\\n        \\\"kubernetesVersion\\\": \\\"1.25.6\\\",\\n        \\\"nodeResourceGroup\\\": \\\"MC_AirflowRG_xxxxxx_AirflowAKSxxxxxx_westus2\\\"\\n    },\\n    \\\"type\\\": \\\"Microsoft.ContainerService/managedClusters\\\"\\n}\\n```\\n\\nStandard_D4_v3 is a balanced VM size offering good performance and availability in WestUS2. Adjust node count and VM size based on workload requirements.\\n\\n---\\n\\n## Step 6: Deploy Apache Airflow using Helm\\n\\nHelm is a package manager for Kubernetes, used to deploy and manage Apache Airflow on AKS.\\n\\nDefine the environment variables for Helm deployment:\\n\\n```bash\\nexport AIRFLOW_RELEASE_NAME_ED432=\\\"airflow\\\"\\nexport AIRFLOW_NAMESPACE_ED432=\\\"airflow\\\"\\n```\\n\\nCreate the namespace and deploy Airflow:\\n\\n```bash\\nkubectl create namespace $AIRFLOW_NAMESPACE_ED432\\n\\nhelm repo add apache-airflow https://airflow.apache.org\\n\\nhelm install $AIRFLOW_RELEASE_NAME_ED432 apache-airflow/airflow \\\\\\n    --namespace $AIRFLOW_NAMESPACE_ED432 \\\\\\n    --set executor=CeleryExecutor \\\\\\n    --set logs.persistence.enabled=true \\\\\\n    --set logs.persistence.storageClassName=default \\\\\\n    --set logs.persistence.size=10Gi\\n```\\n\\nThis command will output results similar to the following:\\n\\n```text\\nNAME: airflow\\nLAST DEPLOYED: Mon Oct 16 14:00:00 2023\\nNAMESPACE: airflow\\nSTATUS: deployed\\nREVISION: 1\\nTEST SUITE: None\\n```\\n\\nEnsure that `kubelogin` is installed and configured correctly to avoid authentication issues. Customize Helm values for resource limits, replica counts, and environment variables based on workload requirements.\"}}, {\"py/object\": \"__main__.Section\", \"name\": \"Summary\", \"requires_test\": false, \"instance\": {\"py/object\": \"summary.Summary\", \"title\": \"Summary\", \"meta_data\": {}, \"content\": \"## Summary\\n\\nThis document detailed the architecture and step-by-step process for deploying a simple Python Flask application to Microsoft Azure using Azure App Service. The purpose of the architecture was to provide a lightweight, fully managed solution for hosting a Flask-based web application, ideal for small-scale projects, prototypes, or educational use cases. By leveraging Azure App Service, developers were able to focus on application development without the need to manage underlying infrastructure.\\n\\nKey decision points included selecting an App Service Plan SKU, choosing an Azure region, configuring scaling options, determining deployment methods, and evaluating the need for persistent storage. The Free tier of the App Service Plan was recommended for demonstration purposes, while higher tiers were suggested for production workloads. Alternatives such as Azure Kubernetes Service, Azure Functions, and Virtual Machines were discussed for scenarios requiring more control, scalability, or customization.\\n\\n### Next Steps\\n\\n* **Test the Application** - Verify the functionality of the deployed Flask application by accessing its URL and ensuring it operates as expected.\\n* **Enable Monitoring** - Set up Azure Monitor or Application Insights to track performance, availability, and cost metrics for the deployed application.\\n* **Optimize for Production** - Evaluate scaling options, upgrade the App Service Plan tier, and integrate CI/CD pipelines for streamlined production deployments.\"}}]}"